import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Flatten,Reshape,InputLayer

train = pd.read_csv('Datasets\9 Credit Card Dataset\creditcard.csv')

train.head()

#train['Class'].nunique()
print(f"The normal class has {train[train['Class'] == 0].shape[0]} samples")
print(f"The anomaly class has {train[train['Class'] == 1].shape[0]} samples")

# Separate features and labels
X = train.drop("Class", axis=1).values
y = train["Class"].values

# Normalize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split into training data (only normal) and test data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print(f"The train_x :{X_train.shape}")
print(f"The train_y :{y_train.shape}")
print(f"The test_X :{X_test.shape}")
print(f"The test_y :{y_test.shape}")

# Use only the normal (Class 0) data for training
X_train_normal = X_train[y_train == 0]

# Define the Autoencoder model
model = Sequential([
    #Encoder Part
    Dense(16, activation='relu', input_shape=(X.shape[1],)),
    Dense(8, activation='relu'),
    #Decoder Part
    Dense(16, activation='relu'),
    Dense(X.shape[1], activation='sigmoid')  # Output layer matches the input shape
])

model.compile(optimizer='adam', loss='mse')

# Train the model on normal data only
history = model.fit(X_train_normal, X_train_normal, 
                    epochs=5, 
                    batch_size=32, 
                    validation_split=0.1, 
                    shuffle=True)

# Plot training and validation loss
plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.legend()
plt.show()

# Calculate reconstruction error for the test set
X_test_pred = model.predict(X_test)
#The Below Reconstruction_error is same as mse
reconstruction_errors = np.mean(np.square(X_test_pred - X_test), axis=1)

# Set a threshold for anomaly detection based on training reconstruction error
threshold = np.percentile(reconstruction_errors, 95)  # 95th percentile

# Flag transactions with reconstruction error above the threshold as anomalies
y_pred = (reconstruction_errors > threshold).astype(int)

# Evaluate performance
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
sns.heatmap(confusion_matrix(y_test,y_pred), annot = True, annot_kws = {"size": 16}, fmt = 'd')
plt.xlabel("predicted labels")
plt.ylabel("True Labels: ")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))